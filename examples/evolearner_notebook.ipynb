{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unlike-landscape",
   "metadata": {},
   "source": [
    "# EvoLearner Notebook\n",
    "This is a jupyter notebook file to execute [EvoLearner](ontolearn.concept_learner.EvoLearner) and generate predictive results. We recommend you to see the [concept learners](05_concept_learners.md) guide before continuing with the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "numerous-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ontolearn.knowledge_base import KnowledgeBase\n",
    "from ontolearn.concept_learner import EvoLearner\n",
    "from ontolearn.learning_problem import PosNegLPStandard\n",
    "from ontolearn.owlapy.model import OWLNamedIndividual, IRI\n",
    "from ontolearn.utils import setup_logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-color",
   "metadata": {},
   "source": [
    "Open `uncle_lp.json` where we have stored the learning problem for the concept of 'Uncle' and the path to the 'family' ontology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "modular-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../examples/uncle_lp.json') as json_file:\n",
    "    settings = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-necklace",
   "metadata": {},
   "source": [
    "Create an instance of the class `KnowledeBase` by using the path that is stored in `settings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wanted-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = KnowledgeBase(path=settings['data_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-creation",
   "metadata": {},
   "source": [
    "Retreive the IRIs of the positive and negative examples of Uncle from `settings` and create an instance of `PosNegLPStandard`. (more info about this [here](02_learning_problem.md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "entitled-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = settings['Uncle']\n",
    "p = set(examples['positive_examples'])\n",
    "n = set(examples['negative_examples'])\n",
    "typed_pos = set(map(OWLNamedIndividual, map(IRI.create, p)))\n",
    "typed_neg = set(map(OWLNamedIndividual, map(IRI.create, n)))\n",
    "lp = PosNegLPStandard(pos=typed_pos, neg=typed_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-tracy",
   "metadata": {},
   "source": [
    "Create a model of EvoLearner and fit the learning problem to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "prescribed-explosion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ontolearn.concept_learner.EvoLearner at 0x1d92907b040>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EvoLearner(knowledge_base=kb, max_runtime=600)\n",
    "model.fit(lp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-monaco",
   "metadata": {},
   "source": [
    "Retrieve top 3 hypotheses and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "proud-dependence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ontolearn.search.EvoLearnerNode'> at 0x0bd309\tMale ⊓ ((∃ married.((∃ married.Sister) ⊔ (∃ hasSibling.Parent))) ⊔ (∃ hasSibling.Parent))\tQuality:1.0\tLength:15\tTree Length:11\tTree Depth:5\t|Indv.|:38\n",
      "<class 'ontolearn.search.EvoLearnerNode'> at 0x0b62f9\tMale ⊓ ((∃ married.PersonWithASibling) ⊔ (∃ hasSibling.Parent))\tQuality:0.97368\tLength:9\tTree Length:7\tTree Depth:3\t|Indv.|:53\n",
      "<class 'ontolearn.search.EvoLearnerNode'> at 0x0ba7a4\tMale ⊓ ((∃ married.PersonWithASibling) ⊔ (∃ hasSibling.Parent))\tQuality:0.97368\tLength:9\tTree Length:7\tTree Depth:3\t|Indv.|:53\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses = list(model.best_hypotheses(n=3))\n",
    "[print(_) for _ in hypotheses]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
