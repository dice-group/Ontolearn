{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "verified-temple",
   "metadata": {},
   "source": [
    "# OCEL Notebook\n",
    "This is a jupyter notebook file to execute [OCEL](ontolearn.concept_learner.OCEL) and generate predictive results. We recommend you to see the [concept learners](05_concept_learners.md) guide before continuing with the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sustainable-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ontolearn.knowledge_base import KnowledgeBase\n",
    "from ontolearn.concept_learner import OCEL\n",
    "from ontolearn.learning_problem import PosNegLPStandard\n",
    "from ontolearn.owlapy.model import OWLNamedIndividual, IRI\n",
    "from ontolearn.utils import setup_logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-colorado",
   "metadata": {},
   "source": [
    "Open `uncle_lp.json` where we have stored the learning problem for the concept of 'Uncle' and the path to the 'family' ontology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "buried-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../examples/uncle_lp.json') as json_file:\n",
    "    settings = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-yellow",
   "metadata": {},
   "source": [
    "Create an instance of the class `KnowledeBase` by using the path that is stored in `settings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "outdoor-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = KnowledgeBase(path=settings['data_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-sucking",
   "metadata": {},
   "source": [
    "Retreive the IRIs of the positive and negative examples of Uncle from `settings` and create an instance of `PosNegLPStandard`. (more info about this [here](02_learning_problem.md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "right-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = settings['Uncle']\n",
    "p = set(examples['positive_examples'])\n",
    "n = set(examples['negative_examples'])\n",
    "typed_pos = set(map(OWLNamedIndividual, map(IRI.create, p)))\n",
    "typed_neg = set(map(OWLNamedIndividual, map(IRI.create, n)))\n",
    "lp = PosNegLPStandard(pos=typed_pos, neg=typed_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-peripheral",
   "metadata": {},
   "source": [
    "Create a model of [OCEL](ontolearn.concept_learner.CELOE) and fit the learning problem to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "permanent-alabama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ontolearn.concept_learner.OCEL at 0x2936feb8820>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OCEL(knowledge_base=kb, max_runtime=600)\n",
    "model.fit(lp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-elevation",
   "metadata": {},
   "source": [
    "Retrieve top 3 hypotheses and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "incoming-debate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ontolearn.search.LBLNode'> at 0x8eb85c\t(¬Female) ⊓ (∀ hasSibling.(∃ hasSibling.(∃ hasSibling.Parent)))\tQuality:0.90476\tHeuristic:0.6479\tDepth:12\tH_exp:13\t|RC|:33\t|Indv.|:95\n",
      "<class 'ontolearn.search.LBLNode'> at 0xb3997c\t(¬Female) ⊓ (∀ hasSibling.(∃ hasSibling.(∃ hasSibling.(∃ hasChild.⊤))))\tQuality:0.90476\tHeuristic:0.63474\tDepth:13\tH_exp:13\t|RC|:5\t|Indv.|:95\n",
      "<class 'ontolearn.search.LBLNode'> at 0xb4f8b4\t(¬Female) ⊓ (∀ hasSibling.(∃ hasSibling.(∃ hasSibling.(∃ hasChild.Person))))\tQuality:0.90476\tHeuristic:0.63474\tDepth:14\tH_exp:13\t|RC|:9\t|Indv.|:95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses = list(model.best_hypotheses(n=3))\n",
    "[print(_) for _ in hypotheses]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
